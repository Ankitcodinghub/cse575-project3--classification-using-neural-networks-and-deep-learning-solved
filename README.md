# cse575-project3--classification-using-neural-networks-and-deep-learning-solved
**TO GET THIS SOLUTION VISIT:** [CSE575 Project3- Classification Using Neural Networks and Deep Learning Solved](https://www.ankitcodinghub.com/product/cse575-project3-classification-using-neural-networks-and-deep-learning-solved/)


---

ðŸ“© **If you need this solution or have special requests:** **Email:** ankitcoding@gmail.com  
ðŸ“± **WhatsApp:** +1 419 877 7882  
ðŸ“„ **Get a quote instantly using this form:** [Ask Homework Questions](https://www.ankitcodinghub.com/services/ask-homework-questions/)

*We deliver fast, professional, and affordable academic help.*

---

<h2>Description</h2>



<div class="kk-star-ratings kksr-auto kksr-align-center kksr-valign-top" data-payload="{&quot;align&quot;:&quot;center&quot;,&quot;id&quot;:&quot;70213&quot;,&quot;slug&quot;:&quot;default&quot;,&quot;valign&quot;:&quot;top&quot;,&quot;ignore&quot;:&quot;&quot;,&quot;reference&quot;:&quot;auto&quot;,&quot;class&quot;:&quot;&quot;,&quot;count&quot;:&quot;4&quot;,&quot;legendonly&quot;:&quot;&quot;,&quot;readonly&quot;:&quot;&quot;,&quot;score&quot;:&quot;5&quot;,&quot;starsonly&quot;:&quot;&quot;,&quot;best&quot;:&quot;5&quot;,&quot;gap&quot;:&quot;4&quot;,&quot;greet&quot;:&quot;Rate this product&quot;,&quot;legend&quot;:&quot;5\/5 - (4 votes)&quot;,&quot;size&quot;:&quot;24&quot;,&quot;title&quot;:&quot;CSE575 Project3-&nbsp;Classification Using Neural Networks and Deep Learning Solved&quot;,&quot;width&quot;:&quot;138&quot;,&quot;_legend&quot;:&quot;{score}\/{best} - ({count} {votes})&quot;,&quot;font_factor&quot;:&quot;1.25&quot;}">

<div class="kksr-stars">

<div class="kksr-stars-inactive">
            <div class="kksr-star" data-star="1" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="2" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="3" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="4" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="5" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
    </div>

<div class="kksr-stars-active" style="width: 138px;">
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
    </div>
</div>


<div class="kksr-legend" style="font-size: 19.2px;">
            5/5 - (4 votes)    </div>
    </div>
In this part, we will revisit the Handwritten Digits Recognition task in Part 1, using a convolutional neural network. The basic dataset is the same MNIST dataset from Part I,

but you may choose to use only a subset for training and testing, if speed performance with the entire dataset becomes a bottleneck. For example, you may use only 6000 samples for training (each digit with 600 samples) and 1000 samples for testing (each digit with 100 samples).

The basic requirement of this part is to experiment with a convolutional neural network with the following parameter settings:

<ul>
<li>The input size is the size of the image (28Ã—28).</li>
<li>The first hidden layer is a convolutional layer, with 6 feature maps. The convolutionkernels are of 3Ã—3 in size. Use stride 1 for convolution.</li>
<li>The convolutional layer is followed by a max pooling layer. The pooling is 2Ã—2 with stride 1.</li>
<li>After max pooling, the layer is connected to the next convolutional layer, with 16 feature maps. Theconvolution kernels are of 3Ã—3 in size. Use stride 1 for convolution.</li>
<li>The second convolutional layer is followed by a max pooling layer. The pooling is 2Ã—2 with stride 1.</li>
<li>After max pooling, the layer is fully connected to the next hidden layer with 120 nodes and relu as theactivation function.</li>
<li>The fully connected layer is followed by another fully connected layer with 84 nodes and relu as theactivation function, then connected to a softmax layer with 10 output nodes (corresponding to the 10 classes).</li>
</ul>
We will train such a network with the training set and then test it on the testing set.

You are required to plot the training error and the testing error as a function of the learning epochs.&nbsp; You are also required to change some of the hyper-parameters (the kernel size, the number of feature maps, etc), and then repeat the experiment and plot training and testing errors under the new setting. These are the minimum requirements. Additional requirements may be added (like

experimenting with different kernel sizes, number of feature maps, ways of doing pooling, or even introducing drop-out in training, etc.).

Algorithm:

Convolutional Neural Network

Resources:

MNIST dataset, Google CoLab

Workspace:

Google CoLab (see file intro_to_colab.docx for more details)

Software:

Google CoLab

Language(s):

Python

Getting Started:

Read this document carefully, as well as&nbsp; additional files included (intro_to_colab.docx and<a href="https://asu.instructure.com/courses/31489/files/10486250/download?wrap=1"><strong> baseline.docx</strong></a> ). For more details about Colab, please go to

<a href="https://colab.research.google.com/notebooks/welcome.ipynb"><strong>https://colab.research.</strong></a><a href="https://colab.research.google.com/notebooks/welcome.ipynb"><strong>g</strong></a><a href="https://colab.research.google.com/notebooks/welcome.ipynb"><strong>oo</strong></a><a href="https://colab.research.google.com/notebooks/welcome.ipynb"><strong>g</strong></a><a href="https://colab.research.google.com/notebooks/welcome.ipynb"><strong>le.com/notebooks/welcome.ip</strong></a><a href="https://colab.research.google.com/notebooks/welcome.ipynb"><strong>y</strong></a><a href="https://colab.research.google.com/notebooks/welcome.ipynb"><strong>nb</strong></a>

<a href="https://colab.research.google.com/notebooks/welcome.ipynb"><strong>(https://colab.research.</strong></a><a href="https://colab.research.google.com/notebooks/welcome.ipynb"><strong>g</strong></a><a href="https://colab.research.google.com/notebooks/welcome.ipynb"><strong>oo</strong></a><a href="https://colab.research.google.com/notebooks/welcome.ipynb"><strong>g</strong></a><a href="https://colab.research.google.com/notebooks/welcome.ipynb"><strong>le.com/notebooks/welcome.ip</strong></a><a href="https://colab.research.google.com/notebooks/welcome.ipynb"><strong>y</strong></a><a href="https://colab.research.google.com/notebooks/welcome.ipynb"><strong>nb) </strong></a><a href="https://colab.research.google.com/notebooks/welcome.ipynb">&nbsp;</a>

Required Tasks:

<ol>
<li>Read <a href="https://asu.instructure.com/courses/31489/files/10217264/download?wrap=1"><strong>docx</strong></a> to get familiar with the platform.</li>
<li>Run the baseline code (<a href="https://asu.instructure.com/courses/31489/files/10486250/download?wrap=1"><strong>docx</strong></a> ) and report the accuracy.</li>
<li>Change the kernel size to 5*5, redo the experiment, plot the learning errors along with the epoch, andreport the testing error and accuracy on the test set.</li>
<li>Change the number of the feature maps in the first and second convolutional layers, redo theexperiment, plot the learning errors along with the epoch, and report the testing error and accuracy on the test set.</li>
<li>Submit a brief report summarizing the above results, along with your code.</li>
</ol>
Optional Tasks:

<ol>
<li>Change the kernel size to 9*9 and redo the experiment and report your results.</li>
<li><a href="https://keras.io/optimizers/">Use another optimizer (it can be chosen from</a><a href="https://keras.io/optimizers/"><strong> https://keras.io/optimizers/</strong></a></li>
</ol>
<a href="https://keras.io/optimizers/"><strong>(https://keras.io/optimizers/) </strong></a><a href="https://keras.io/optimizers/">) and at least 3 different learning rate to redo the expe</a>riment, and report the accuracy vs learning rate on the test set.

<ol start="3">
<li>Use average pooling and redo the experiment an0d report your results.</li>
</ol>
Optional tasks are to be explored on your own if you are interested and have extra time for them. No submission is required on the optional tasks. No grading will be done even if you submit any work on the optional tasks. No credit will be assigned to them even if you submit them. (So, please do not submit any work on optional tasks.)
